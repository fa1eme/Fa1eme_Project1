{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE6eaqdLhSPX"
      },
      "source": [
        "Split_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx9dgFyDIBG4"
      },
      "outputs": [],
      "source": [
        "char_to_num = layers.StringLookup(\n",
        "    vocabulary=list(characters), mask_token=None\n",
        ")\n",
        "\n",
        "num_to_char = layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
        ")\n",
        "\n",
        "def split_data(images, labels, train_size=0.8, shuffle=True):\n",
        "    size = len(images)\n",
        "    np.random.seed(42)\n",
        "    indices = np.arange(size)\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    train_samples = int(size * train_size)\n",
        "    val_test_size = (size - train_samples) // 2\n",
        "    x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n",
        "    x_valid, y_valid = images[indices[train_samples:train_samples+val_test_size]], labels[indices[train_samples:train_samples+val_test_size]]\n",
        "    x_test, y_test = images[indices[train_samples+val_test_size:]], labels[indices[train_samples+val_test_size:]]\n",
        "    return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
        "\n",
        "x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(np.array(path_list), np.array(labels_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkMYzcg6iE-0"
      },
      "source": [
        "Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0DhHKp8IDSi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "char_to_num = layers.StringLookup(\n",
        "    vocabulary=list(characters), mask_token=None\n",
        ")\n",
        "\n",
        "num_to_char = layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
        ")\n",
        "\n",
        "def split_data(images, labels, train_size=0.8, shuffle=True):\n",
        "    size = len(images)\n",
        "    np.random.seed(42)\n",
        "    indices = np.arange(size)\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    train_samples = int(size * train_size)\n",
        "    val_test_size = (size - train_samples) // 2\n",
        "    x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n",
        "    x_valid, y_valid = images[indices[train_samples:train_samples+val_test_size]], labels[indices[train_samples:train_samples+val_test_size]]\n",
        "    x_test, y_test = images[indices[train_samples+val_test_size:]], labels[indices[train_samples+val_test_size:]]\n",
        "    return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
        "\n",
        "x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(np.array(path_list), np.array(labels_list))\n",
        "batch_size = 16\n",
        "img_height = 50\n",
        "padding_token = 11\n",
        "\n",
        "def augment_image_targeted(img, label):\n",
        "    label = tf.strings.to_number(label, out_type=tf.int32)\n",
        "\n",
        "    if tf.equal(label, 2):\n",
        "        img = tf.image.random_contrast(img, lower=0.7, upper=1.3)\n",
        "        img = tf.image.random_brightness(img, max_delta=0.2)\n",
        "    elif tf.equal(label, 5):\n",
        "        img = tf.image.random_flip_left_right(img)\n",
        "        img = tf.image.random_contrast(img, lower=0.7, upper=1.3)\n",
        "    elif tf.equal(label, 3):\n",
        "        img = tf.image.random_flip_up_down(img)\n",
        "    elif tf.equal(label, 4):\n",
        "        img = tf.image.random_flip_left_right(img)\n",
        "    elif tf.equal(label, 0):\n",
        "        img = tf.image.random_brightness(img, max_delta=0.2)\n",
        "    elif tf.equal(label, 7):\n",
        "        img = tf.image.random_flip_left_right(img)\n",
        "        img = tf.image.random_contrast(img, lower=0.7, upper=1.3)\n",
        "    elif tf.equal(label, 8):\n",
        "        angles = tf.random.uniform([], -0.2, 0.2)\n",
        "        radians = angles * np.pi\n",
        "        img = tf.image.rot90(img, k=tf.cast(tf.random.uniform([], 0, 4), tf.int32))\n",
        "        img = tf.image.random_brightness(img, max_delta=0.2)\n",
        "    elif tf.equal(label, 1):\n",
        "        img = tf.image.random_flip_left_right(img)\n",
        "    elif tf.equal(label, 6):\n",
        "        img = tf.image.random_flip_up_down(img)\n",
        "    elif tf.equal(label, 9):\n",
        "        img = tf.image.random_flip_left_right(img)\n",
        "\n",
        "    img = tf.image.random_brightness(img, max_delta=0.2)\n",
        "    img = tf.image.random_contrast(img, lower=0.7, upper=1.3)\n",
        "    return img, label\n",
        "\n",
        "def encode_single_sample(img_path, label):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels=1)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, [img_height, tf.shape(img)[1]])\n",
        "    img = tf.transpose(img, perm=[1, 0, 2])\n",
        "\n",
        "    label = tf.strings.as_string(label)\n",
        "    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
        "    label = char_to_num(label)\n",
        "\n",
        "    length = tf.shape(label)[0]\n",
        "    pad_amount = max_length - length\n",
        "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
        "\n",
        "    return img, label\n",
        "\n",
        "padded_shapes = ([None, None, 1], [None])\n",
        "padding_values = (0.0, np.int64(0))\n",
        "\n",
        "def map_fn(image, label):\n",
        "    return {'image': image, 'label': label}\n",
        "\n",
        "train_dataset = (\n",
        "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .map(augment_image_targeted, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size, padded_shapes=padded_shapes, padding_values=padding_values)\n",
        "    .map(map_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    .cache()\n",
        ")\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size, padded_shapes=padded_shapes, padding_values=padding_values)\n",
        "    .map(map_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    .cache()\n",
        ")\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = (\n",
        "    test_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size, padded_shapes=padded_shapes, padding_values=padding_values)\n",
        "    .map(map_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
